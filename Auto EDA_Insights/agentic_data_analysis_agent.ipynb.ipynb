{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb58bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas matplotlib openai streamlit python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef314ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --------------------------------\n",
    "# CONFIG\n",
    "# --------------------------------\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# --------------------------------\n",
    "# STEP 1: SCHEMA INSPECTION\n",
    "# --------------------------------\n",
    "def inspect_schema(df):\n",
    "    schema = []\n",
    "    for col in df.columns:\n",
    "        schema.append({\n",
    "            \"column\": col,\n",
    "            \"dtype\": str(df[col].dtype),\n",
    "            \"missing_pct\": round(df[col].isna().mean() * 100, 2),\n",
    "            \"unique_values\": int(df[col].nunique())\n",
    "        })\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a98f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# STEP 2: ANALYSIS PLANNER (SELF-DECIDING)\n",
    "# --------------------------------\n",
    "def plan_analysis(schema):\n",
    "    prompt = f\"\"\"\n",
    "You are a senior data analyst.\n",
    "\n",
    "Based on the dataset schema below:\n",
    "1. Identify dataset type\n",
    "2. Identify target variable (if any)\n",
    "3. Decide analyses to perform\n",
    "4. Decide analyses to skip\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Respond ONLY in JSON with:\n",
    "dataset_type, target_variable, recommended_analyses, skip_analyses\n",
    "\"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30248c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# STEP 3: HYPOTHESIS GENERATION\n",
    "# --------------------------------\n",
    "def generate_hypotheses(schema, target):\n",
    "    prompt = f\"\"\"\n",
    "Generate 3 to 5 testable hypotheses for this dataset.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Target variable:\n",
    "{target}\n",
    "\n",
    "Return JSON array with:\n",
    "hypothesis, test_method, required_columns\n",
    "\"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a93dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# STEP 4: DETERMINISTIC TESTS\n",
    "# --------------------------------\n",
    "def test_age_churn(df, target):\n",
    "    df = df.dropna(subset=[\"Age\", target])\n",
    "    df[\"age_bucket\"] = pd.cut(df[\"Age\"], bins=[0,30,45,60,100])\n",
    "    return df.groupby(\"age_bucket\")[target].mean()\n",
    "\n",
    "def test_correlation(df, col, target):\n",
    "    df = df[[col, target]].dropna()\n",
    "    return df.corr().iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870dd0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# STEP 5: HYPOTHESIS EVALUATION\n",
    "# --------------------------------\n",
    "def evaluate_hypotheses(df, hypotheses, target):\n",
    "    results = []\n",
    "\n",
    "    for h in hypotheses:\n",
    "        try:\n",
    "            if h[\"test_method\"].lower().startswith(\"compare\") and \"age\" in h[\"required_columns\"]:\n",
    "                output = test_age_churn(df, target)\n",
    "                decision = \"Accepted\" if output.max() - output.min() > 0.1 else \"Rejected\"\n",
    "\n",
    "                results.append({\n",
    "                    \"hypothesis\": h[\"hypothesis\"],\n",
    "                    \"result\": decision,\n",
    "                    \"evidence\": output.to_string()\n",
    "                })\n",
    "\n",
    "            elif h[\"test_method\"].lower().startswith(\"correlation\"):\n",
    "                corr = test_correlation(df, h[\"required_columns\"][0], target)\n",
    "                decision = \"Accepted\" if abs(corr) > 0.3 else \"Rejected\"\n",
    "\n",
    "                results.append({\n",
    "                    \"hypothesis\": h[\"hypothesis\"],\n",
    "                    \"result\": decision,\n",
    "                    \"evidence\": f\"Correlation = {round(corr, 3)}\"\n",
    "                })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"hypothesis\": h[\"hypothesis\"],\n",
    "                \"result\": \"Error\",\n",
    "                \"evidence\": str(e)\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30fc642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# STEP 6: INTERPRET RESULTS\n",
    "# --------------------------------\n",
    "def interpret_results(results):\n",
    "    prompt = f\"\"\"\n",
    "Interpret the following hypothesis test results.\n",
    "Explain insights in business terms.\n",
    "\n",
    "Results:\n",
    "{results}\n",
    "\"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3385abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# MAIN AGENT RUNNER\n",
    "# --------------------------------\n",
    "def run_agent(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    schema = inspect_schema(df)\n",
    "    plan = plan_analysis(schema)\n",
    "\n",
    "    print(\"\\n===== AGENT DECISION =====\")\n",
    "    print(\"Dataset Type:\", plan[\"dataset_type\"])\n",
    "    print(\"Target Variable:\", plan[\"target_variable\"])\n",
    "    print(\"Analyses to Run:\", plan[\"recommended_analyses\"])\n",
    "    print(\"Analyses Skipped:\", plan[\"skip_analyses\"])\n",
    "\n",
    "    hypotheses = generate_hypotheses(schema, plan[\"target_variable\"])\n",
    "    print(\"\\n===== GENERATED HYPOTHESES =====\")\n",
    "    for h in hypotheses:\n",
    "        print(\"-\", h[\"hypothesis\"])\n",
    "\n",
    "    results = evaluate_hypotheses(df, hypotheses, plan[\"target_variable\"])\n",
    "    print(\"\\n===== HYPOTHESIS RESULTS =====\")\n",
    "    for r in results:\n",
    "        print(f\"\\n{r['hypothesis']}\")\n",
    "        print(\"Decision:\", r[\"result\"])\n",
    "        print(\"Evidence:\\n\", r[\"evidence\"])\n",
    "\n",
    "    interpretation = interpret_results(results)\n",
    "    print(\"\\n===== BUSINESS INTERPRETATION =====\")\n",
    "    print(interpretation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eea28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# ENTRY POINT\n",
    "# --------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_agent(\"sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a91b7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
